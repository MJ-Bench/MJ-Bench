# import hpsv2
# from PIL import Image
# from io import BytesIO
# import requests
# import torch
# import numpy as np
#
# def open_image(image):
#     if isinstance(image, bytes):
#         image = Image.open(BytesIO(image))
#     image = image.convert("RGB")
#     return image
#
# # imgs_path can be a list of image paths, with the images generated by the same prompt
# # or image path of string type
# # or image of PIL.Image.Image type
# prompt = "an orange cat and a grey cat are lying together."
# imgs_path = ['../clipscore/example/images/image2.jpg']
#
# result = hpsv2.score(imgs_path, prompt, hps_version="v2.1")
# print(f"type: {type(result[0])}")
#
# print(f"The score of the image is: {result}")

# --------------------------------------------------------------------------------
import hpsv2
from PIL import Image
import torch
import json
from io import BytesIO
import clip
import warnings
from packaging import version
import sklearn.preprocessing
from tqdm import tqdm
import numpy as np
from datasets import load_dataset
import os
from transformers import BlipProcessor, BlipModel, AutoModel, AutoProcessor, AutoModelForSeq2SeqLM, AutoModelForCausalLM
from transformers import BlipProcessor, BlipForImageTextRetrieval

def open_image(image):
    if isinstance(image, bytes):
        image = Image.open(BytesIO(image))
    image = image.convert("RGB")
    return image

def get_pred(prob_0, prob_1, threshold):
    if abs(prob_1 - prob_0) <= threshold:
        pred = "tie"
    elif prob_0 > prob_1:
        pred = "0"
    else:
        pred = "1"
    return pred

def get_label(example):
    if example["label_0"] == 0.5:
        label = "tie"
    elif example["label_0"] == 1:
        label = "0"
    else:
        label = "1"
    return label

if __name__ == "__main__":
    warnings.filterwarnings("ignore")
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # Load dataset
    dataset = load_dataset("yuvalkirstain/pickapic_v1", streaming=True)
    dataset = dataset['validation_unique']

    image_buffer = "/home/czr/DMs-RLAIF/dataset/pickapic_v1/validation_unique"
    all_images = os.listdir(image_buffer)
    image_dict = {}
    for image_dir in all_images:
        image_id = image_dir.split(".jpg")[0]
        image_dict[image_id] = image_dir

    print("len of image_dict", len(image_dict))
    print("dataset", dataset)

    # Define save directory
    save_dir = "../result/validation_HPSv2score_eval_0.00.json"
    data_list = []
    threshold = 0.0

    for id, example in tqdm(enumerate(dataset)):
        # if id > 3:
        #     break

        new_item = {}

        # # Calculate HPSv2Score for image 0
        # image_0_path = os.path.join(image_buffer, image_dict[example["image_0_uid"]])
        # score_0 = hpsv2.score(image_0_path, example["caption"], hps_version="v2.1").tolist()
        # print(score_0)
        #
        # # Calculate HPSv2Score for image 1
        # image_1_path = os.path.join(image_buffer, image_dict[example["image_1_uid"]])
        # score_1 = hpsv2.score(image_1_path, example["caption"], hps_version="v2.1").tolist()
        # print(score_1)

        # Calculate HPSv2Score
        image_0_path = os.path.join(image_buffer, image_dict[example["image_0_uid"]])
        image_1_path = os.path.join(image_buffer, image_dict[example["image_1_uid"]])
        imgs_path = [image_0_path, image_1_path]
        scores = hpsv2.score(imgs_path, example["caption"], hps_version="v2.1")
        scores = np.array(scores).tolist()

        print(f"Image 0: {scores[0]}, Image 1: {scores[1]}")

        pred = get_pred(scores[0], scores[1], threshold)
        label = get_label(example)

        # Create new item
        new_item["id"] = id
        new_item["caption"] = example["caption"]
        new_item["ranking_id"] = example["ranking_id"]
        new_item["image_0_uid"] = example["image_0_uid"]
        new_item["image_1_uid"] = example["image_1_uid"]
        new_item["score_0"] = scores[0]
        new_item["score_1"] = scores[1]
        new_item["label"] = label
        new_item["pred"] = pred

        data_list.append(new_item)

    # Save data to JSON file
    with open(save_dir, 'w', encoding='utf-8') as f:
        json.dump(data_list, f, indent=4, ensure_ascii=False)
