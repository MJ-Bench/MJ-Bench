{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 修改caption_blur.json"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "813a74bda4ba48ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取原始JSON文件\n",
    "with open('../artifacts/blur_dataset/captions_blur.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 修改每个样本\n",
    "for sample in data:\n",
    "    # sample[\"sharp_image\"] = sample.pop(\"image_name\")\n",
    "    sample[\"motion_blur_image\"] = sample[\"sharp_image\"][:sample[\"sharp_image\"].find(\"_S.\")]+'_M.'+sample[\"sharp_image\"][sample[\"sharp_image\"].find(\"_S.\")+len(\"_S.\"):]\n",
    "    sample[\"defocused_blur_image\"] = sample[\"sharp_image\"][:sample[\"sharp_image\"].find(\"_S.\")]+'_F.'+sample[\"sharp_image\"][sample[\"sharp_image\"].find(\"_S.\")+len(\"_S.\"):]\n",
    "\n",
    "# 保存修改后的JSON文件\n",
    "with open('../artifacts/blur_dataset/captions_blur.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d047ca676295d3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取原始JSON文件\n",
    "with open('../artifacts/mpii/captions_mpii.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 修改每个样本\n",
    "for sample in data:\n",
    "    sample[\"label_0\"] = 1\n",
    "\n",
    "# 保存修改后的JSON文件\n",
    "with open('../artifacts/mpii/captions_mpii.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e862adb209f2189",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 修改caption_human"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40aaefa491a9b0a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 读取原始JSON文件\n",
    "with open('../artifacts/objects_indoor/captions_objects.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 修改每个样本\n",
    "for sample in data:\n",
    "    sample[\"image_0\"]=sample.pop(\"image_name\")\n",
    "\n",
    "# 保存修改后的JSON文件\n",
    "with open('../artifacts/objects_indoor/captions_objects.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4accbd526d42e42a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 读取json文件\n",
    "with open('../artifacts/mpii/captions_mpii.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 指定包含jpg文件的目录\n",
    "jpg_directory = '../artifacts/mpii/examples_mpii'\n",
    "\n",
    "# 遍历每条数据\n",
    "for i, item in enumerate(data):\n",
    "    # 获取image_name\n",
    "    image_name = item['image_name']\n",
    "    image_name = image_name.split('.')[0]\n",
    "    \n",
    "    # 在目录中查找含有image_name的文件名\n",
    "    matched_files = [file for file in os.listdir(jpg_directory) if image_name in file]\n",
    "    \n",
    "    # 为每个匹配的文件名添加标签并保存到json中\n",
    "    for j, matched_file in enumerate(matched_files):\n",
    "        # 构建标签名称\n",
    "        label_name = f'image_{j}'\n",
    "        # 更新json数据\n",
    "        data[i][label_name] = matched_file\n",
    "\n",
    "# 将更新后的数据保存回json文件中\n",
    "with open('../artifacts/mpii/your_updated_json_file.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e40c9bf48358d953",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Initialize an empty list to store extracted data\n",
    "extracted_data = []\n",
    "\n",
    "# Open the JSONL file for reading\n",
    "with open('../safety/llava15_13b_inpainting_short_caption.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        # Load each line as JSON\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        # Extract id and answer\n",
    "        image_id = data['id']\n",
    "        caption = data['answer']\n",
    "        \n",
    "        # Modify keys\n",
    "        new_data = {'image_0': image_id[image_id.find('_')+len('_'):], 'image_1': image_id, 'caption': caption, 'label_0': 1}\n",
    "        \n",
    "        # Append the modified data to the list\n",
    "        extracted_data.append(new_data)\n",
    "\n",
    "# Save the extracted data to a JSON file\n",
    "with open('../safety/extracted_data.json', 'w') as json_file:\n",
    "    json.dump(extracted_data, json_file, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537ad2069dff7125",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d3509cb3df6397a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "def get_pred(prob_0, prob_1, threshold=0.0):\n",
    "    if abs(prob_1 - prob_0) <= threshold:\n",
    "        pred = \"tie\"\n",
    "    elif prob_0 > prob_1:\n",
    "        pred = \"0\"\n",
    "    else:\n",
    "        pred = \"1\"\n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_label(example):\n",
    "    if example[\"label_0\"] == 0.5:\n",
    "        label = \"tie\"\n",
    "    elif example[\"label_0\"] == 1:\n",
    "        label = \"0\"\n",
    "    else:\n",
    "        label = \"1\"\n",
    "    return label\n",
    "\n",
    "base_dir = \"./result/pickscore_v1\"\n",
    "file_names = [\"mpii0.0.json\", \"nsfw0.0.json\"]\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        \n",
    "    for example in data:\n",
    "        pred = get_pred(example[\"score_0\"], example[\"score_1\"])\n",
    "        example[\"pred\"] = pred\n",
    "        \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f07761cce38c0ebd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "pick_score_dir = \"../result/acc/aesthetics/blur0.0.json\"\n",
    "\n",
    "with open(pick_score_dir, \"r\") as f:\n",
    "    pick_score = json.load(f)\n",
    "\n",
    "def get_pred(pred):\n",
    "    if pred == \"0\":\n",
    "        preference = 0\n",
    "    elif pred == \"1\":\n",
    "        preference = 1\n",
    "    else:\n",
    "        preference = 0.5\n",
    "    return preference\n",
    "\n",
    "human_preference = []\n",
    "humanscore_preference = []\n",
    "pickscore_preference = []\n",
    "\n",
    "for pick_item in pick_score:\n",
    "    pick_pred = pick_item[\"pred\"]\n",
    "    pick_preference = get_pred(pick_pred)\n",
    "    pickscore_preference.append(pick_preference)\n",
    "    human_pred = pick_item[\"label\"]\n",
    "    human_preference = get_pred(human_pred)\n",
    "    humanscore_preference.append(human_preference)\n",
    "\n",
    "print(\"humanscore_preference\", len(humanscore_preference))\n",
    "print(\"pickscore_preference\", len(pickscore_preference))\n",
    "\n",
    "print(\"Pick Preference Tie: \", pickscore_preference.count(0.5))\n",
    "print(\"Human Preference Tie: \", humanscore_preference.count(0.5))\n",
    "\n",
    "sum_all = 0\n",
    "sum_valid = 0\n",
    "for human, pick in zip(humanscore_preference, pickscore_preference):\n",
    "    if human == 0.5 or pick == 0.5:\n",
    "        continue\n",
    "    elif human == pick:\n",
    "        sum_all += 1\n",
    "        sum_valid += 1\n",
    "    else:\n",
    "        sum_all += 1\n",
    "\n",
    "print(f\"filter out {len(humanscore_preference)-sum_all} samples\")\n",
    "print(f\"Pick filter tie Accuracy: {sum_valid/sum_all}\")\n",
    "\n",
    "sum_all = 0\n",
    "sum_valid = 0\n",
    "sum_tie = 0\n",
    "pick_filtered_score = []\n",
    "for human, pick in zip(humanscore_preference, pickscore_preference):\n",
    "    if human != 0.5:\n",
    "        pick_filtered_score.append(pick)\n",
    "    if human == 0.5:\n",
    "        continue\n",
    "    elif human == pick:\n",
    "        sum_all += 1\n",
    "        sum_valid += 1\n",
    "    else:\n",
    "        sum_all += 1\n",
    "    \n",
    "    if pick == 0.5:\n",
    "        sum_tie += 1\n",
    "\n",
    "print(f\"re-introduce ties {sum_tie} samples\")\n",
    "print(f\"re-introduce filter out {len(humanscore_preference)-sum_all} samples\")\n",
    "print(f\"re-introduce Pick filter tie Accuracy: {sum_valid/sum_all}\")\n",
    "\n",
    "pearson_corr, _ = pearsonr(pick_filtered_score, humanscore_preference)\n",
    "print(f\"Pickscore Pearson Correlation Coefficient: {pearson_corr}\")\n",
    "\n",
    "kappa = cohen_kappa_score(pick_filtered_score, humanscore_preference)\n",
    "print(f\"Human-Pick Cohen's Kappa: {kappa}\")\n",
    "\n",
    "mse = mean_squared_error(pick_filtered_score, humanscore_preference)\n",
    "print(f\"Pick-Human MSE: {mse}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9d50393e1281f95",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### json2txt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36441c5d7bb4f2f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 从JSON文件中读取数据\n",
    "data_path = '../artifacts/objects_indoor/captions_objects.json'\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 创建一个txt文件来写入coco_caption\n",
    "with open('artifacts_human_finetune_prompt.txt', 'a', encoding='utf-8') as f:\n",
    "    for sample in data:\n",
    "        caption = sample['caption']\n",
    "        f.write(caption + '\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T12:15:55.398097900Z",
     "start_time": "2024-05-27T12:15:55.389098200Z"
    }
   },
   "id": "15e8f29c9b90c962",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
